
step.modules.decoder
====================

.. py:module:: step.modules.decoder


Overview
--------

.. list-table:: Classes
   :header-rows: 0
   :widths: auto
   :class: summarytable

   * - :py:obj:`Exp <step.modules.decoder.Exp>`
     - Base class for all neural network modules.
   * - :py:obj:`ProbDecoder <step.modules.decoder.ProbDecoder>`
     - ProbDecoder is a probabilistic decoder to estimate the parameters of the output distribution(zinb or nb).




Classes
-------

.. py:class:: Exp

   Bases: :py:obj:`torch.nn.Module`

   Base class for all neural network modules.

   Your models should also subclass this class.

   Modules can also contain other Modules, allowing to nest them in
   a tree structure. You can assign the submodules as regular attributes::

       import torch.nn as nn
       import torch.nn.functional as F

       class Model(nn.Module):
           def __init__(self):
               super().__init__()
               self.conv1 = nn.Conv2d(1, 20, 5)
               self.conv2 = nn.Conv2d(20, 20, 5)

           def forward(self, x):
               x = F.relu(self.conv1(x))
               return F.relu(self.conv2(x))

   Submodules assigned in this way will be registered, and will have their
   parameters converted too when you call :meth:`to`, etc.

   .. note::
       As per the example above, an ``__init__()`` call to the parent class
       must be made before assignment on the child.

   :ivar training: Boolean represents whether this module is in training or
                   evaluation mode.
   :vartype training: bool

   Initializes internal Module state, shared by both nn.Module and ScriptModule.


   .. rubric:: Overview


   .. list-table:: Methods
      :header-rows: 0
      :widths: auto
      :class: summarytable

      * - :py:obj:`forward <step.modules.decoder.Exp.forward>`\ (input)
        - \-


   .. rubric:: Members

   .. py:method:: forward(input)




.. py:class:: ProbDecoder(input_dim=3000, hidden_dim=128, n_hidden_layers=1, output_dim=64, norm='batch', dist='zinb', skip_dim=0, use_skip=False, num_batches: int = 1, use_l_scale: bool = False, activation: Literal[softplus, softmax] | None = None)

   Bases: :py:obj:`torch.nn.Module`

   ProbDecoder is a probabilistic decoder to estimate the parameters of the output distribution(zinb or nb).

   .. attribute:: args

      The arguments to initialize the model.

      :type: dict

   Initialize the ProbDecoder.

   :param input_dim: The input dimension.
   :type input_dim: int
   :param hidden_dim: The hidden dimension.
   :type hidden_dim: int
   :param n_hidden_layers: The number of hidden layers.
   :type n_hidden_layers: int
   :param output_dim: The output dimension.
   :type output_dim: int
   :param norm: The normalization method. Default is "batch".
   :type norm: str
   :param dist: The distribution of the output. Default is "zinb".
   :type dist: str
   :param skip_dim: The dimension of the skip connection. Default is 0.
   :type skip_dim: int
   :param use_skip: Whether to use skip connection. Default is False.
   :type use_skip: bool


   .. rubric:: Overview


   .. list-table:: Methods
      :header-rows: 0
      :widths: auto
      :class: summarytable

      * - :py:obj:`forward <step.modules.decoder.ProbDecoder.forward>`\ (z, library, batch_label, z_)
        - Forward pass of the ProbDecoder.
      * - :py:obj:`ffn_ <step.modules.decoder.ProbDecoder.ffn_>`\ (z, z_)
        - Forward pass of the feedforward network.
      * - :py:obj:`dropout_ <step.modules.decoder.ProbDecoder.dropout_>`\ (z, z_)
        - Dropout logoit of the output distribution.
      * - :py:obj:`copy <step.modules.decoder.ProbDecoder.copy>`\ (with_param)
        - Copy the model.


   .. rubric:: Members

   .. py:method:: forward(z, library, batch_label=None, z_=None)

      Forward pass of the ProbDecoder.

      :param z: The input tensor.
      :type z: torch.Tensor
      :param library: The library size.
      :type library: torch.Tensor
      :param z_: The input tensor of the skip connection. Default is None.
      :type z_: torch.Tensor

      :returns: The rate of the output distribution.
                torch.Tensor: The dropout of the output distribution.
                torch.Tensor: The scale of the output distribution.
      :rtype: torch.Tensor


   .. py:method:: ffn_(z, z_=None)

      Forward pass of the feedforward network.

      :param z: The input tensor.
      :type z: torch.Tensor
      :param z_: The input tensor of the skip connection. Default is None.
      :type z_: torch.Tensor

      :returns: The output tensor.
      :rtype: torch.Tensor


   .. py:method:: dropout_(z, z_=None)

      Dropout logoit of the output distribution.

      :param z: The input tensor.
      :type z: torch.Tensor
      :param z_: The input tensor of the skip connection. Default is None.
      :type z_: torch.Tensor

      :returns: The dropout logit of the output distribution.
      :rtype: torch.Tensor


   .. py:method:: copy(with_param=True)

      Copy the model.

      :param with_param: Whether to copy the parameters. Default is True.
      :type with_param: bool

      :returns: The copied model.
      :rtype: ProbDecoder







